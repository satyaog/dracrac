[{"paper_id": "bdcc5f8d291542bf7ad0ec36480988ab", "title": "MAPL: Parameter-Efficient Adaptation of Unimodal Pre-Trained Models for Vision-Language Few-Shot Prompting", "abstract": "Large pre-trained models have proved to be remarkable zero- and (prompt-based) few-shot learners in unimodal vision and language tasks. We propose MAPL, a simple and parameter-efficient method that reuses frozen pre-trained unimodal models and leverages their strong generalization capabilities in multimodal vision-language (VL) settings. MAPL learns a lightweight mapping between the representation spaces of unimodal models using aligned image-text data, and can generalize to unseen VL tasks from just a few in-context examples. The small number of trainable parameters makes MAPL effective at low-data and in-domain learning. Moreover, MAPL\u2019s modularity enables easy extension to other pre-trained models. Extensive experiments on several visual question answering and image captioning benchmarks show that MAPL achieves superior or competitive performance compared to similar methods while training orders of magnitude fewer parameters. MAPL can be trained in just a few hours using modest computational resources and public datasets. We release our code and pre-trained model weights at https://github.com/oscmansan/mapl.", "authors": [{"author": {"author_id": "a9954c19c19e6d8087c6df8de5d10271", "name": "Oscar Ma\u00f1as", "links": [{"type": "semantic_scholar", "link": "1796269096"}, {"type": "xplore", "link": "37088889151"}]}, "affiliations": [{"institution_id": "1fb8b4e60a6fd94aca7cfbfefd143cbe", "name": "4 Mila, Universit\u00e9 de Montr\u00e9al \u2666 ServiceNow Research \u2665 DeepMind", "category": "academia"}]}, {"author": {"author_id": "d2bc00adb65bbe840037193ff3664993", "name": "Pau Rodriguez", "links": [{"type": "openreview", "link": "~Pau_Rodriguez2"}, {"type": "semantic_scholar", "link": "117849477"}, {"type": "semantic_scholar", "link": "2067974906"}, {"type": "semantic_scholar", "link": "2121428093"}, {"type": "semantic_scholar", "link": "2140428838"}, {"type": "semantic_scholar", "link": "2257190056"}, {"type": "semantic_scholar", "link": "2285026068"}, {"type": "xplore", "link": "37533541500"}]}, "affiliations": [{"institution_id": "1fb8b4e60a6fd94aca7cfbfefd143cbe", "name": "4 Mila, Universit\u00e9 de Montr\u00e9al \u2666 ServiceNow Research \u2665 DeepMind", "category": "academia"}]}, {"author": {"author_id": "c79fe712315e62a0537b9b9779b2cf48", "name": "Saba Ahmadi", "links": [{"type": "semantic_scholar", "link": "12841008"}, {"type": "semantic_scholar", "link": "2120590362"}]}, "affiliations": [{"institution_id": "1fb8b4e60a6fd94aca7cfbfefd143cbe", "name": "4 Mila, Universit\u00e9 de Montr\u00e9al \u2666 ServiceNow Research \u2665 DeepMind", "category": "academia"}]}, {"author": {"author_id": "9bee6a15036e4785b5f52f237bf48661", "name": "Aida Nematzadeh", "links": [{"type": "semantic_scholar", "link": "3208081"}]}, "affiliations": [{"institution_id": "1fb8b4e60a6fd94aca7cfbfefd143cbe", "name": "4 Mila, Universit\u00e9 de Montr\u00e9al \u2666 ServiceNow Research \u2665 DeepMind", "category": "academia"}]}, {"author": {"author_id": "8bed3922c1d6d7b374977ab55d495c34", "name": "Yash Goyal", "links": [{"type": "semantic_scholar", "link": "37226164"}]}, "affiliations": [{"institution_id": "1fb8b4e60a6fd94aca7cfbfefd143cbe", "name": "4 Mila, Universit\u00e9 de Montr\u00e9al \u2666 ServiceNow Research \u2665 DeepMind", "category": "academia"}]}, {"author": {"author_id": "8d03287b9ec960332f5641912cd95e56", "name": "Aishwarya Agrawal", "links": [{"type": "bio", "link": "aishwarya-agrawal"}, {"type": "email.mila", "link": "aishwarya.agrawal@mila.quebec"}, {"type": "mag", "link": "2117267436"}, {"type": "openreview", "link": "~Aishwarya_Agrawal1"}, {"type": "semantic_scholar", "link": "2293394830"}, {"type": "semantic_scholar", "link": "2801949"}, {"type": "wpid_en", "link": "38508"}, {"type": "wpid_fr", "link": "38504"}, {"type": "xplore", "link": "37085397548"}, {"type": "xplore", "link": "37085742308"}, {"type": "xplore", "link": "37087883810"}]}, "affiliations": [{"institution_id": "1fb8b4e60a6fd94aca7cfbfefd143cbe", "name": "4 Mila, Universit\u00e9 de Montr\u00e9al \u2666 ServiceNow Research \u2665 DeepMind", "category": "academia"}]}], "releases": [{"venue": {"venue_id": "20871990ac7b2d3d4d891a071ec99e35", "name": "EACL", "type": "journal", "date": {"text": "2023", "timestamp": 1672549200, "precision": 1}, "links": [], "publisher": null, "series": "", "volume": null}, "peer_reviewed": true, "status": "published", "pages": "2515-2540"}], "topics": [{"name": "Computer Science"}], "links": [{"type": "doi.abstract", "link": "10.18653/v1/2023.eacl-main.185", "url": "https://doi.org/10.18653/v1/2023.eacl-main.185"}, {"type": "doi.abstract", "link": "10.48550/arXiv.2210.07179", "url": "https://doi.org/10.48550/arXiv.2210.07179"}, {"type": "arxiv.abstract", "link": "2210.07179", "url": "https://arxiv.org/abs/2210.07179"}, {"type": "arxiv.pdf", "link": "2210.07179", "url": "https://arxiv.org/pdf/2210.07179.pdf"}, {"type": "dblp.abstract", "link": "conf/eacl/ManasLANGA23", "url": "https://dblp.uni-trier.de/rec/conf/eacl/ManasLANGA23"}, {"type": "pdf", "link": "http://export.arxiv.org/pdf/2210.07179"}, {"type": "semantic_scholar.abstract", "link": "1f86bf1e334200ec0481349255559fbfe7a33caa", "url": "https://www.semanticscholar.org/paper/1f86bf1e334200ec0481349255559fbfe7a33caa"}, {"type": "corpusid", "link": "252873086"}, {"type": "acl", "link": "2023.eacl-main.185"}], "flags": [{"name": "validation", "value": 1}], "validated": true, "citation_count": 0, "excerpt": null}, {"paper_id": "8b47021a0443f42f1f142dd0b39933c7", "title": "Measuring Progress in Fine-grained Vision-and-Language Understanding", "abstract": "While pretraining on large-scale image\u2013text data from the Web has facilitated rapid progress on many vision-and-language (V&L) tasks, recent work has demonstrated that pretrained models lack \u201cfine-grained\u201d understanding, such as the ability to recognise relationships, verbs, and numbers in images. This has resulted in an increased interest in the community to either develop new benchmarks or models for such capabilities. To better understand and quantify progress in this direction, we investigate four competitive V&L models on four fine-grained benchmarks. Through our analysis, we find that X-VLM (Zeng et al., 2022) consistently outperforms other baselines, and that modelling innovations can impact performance more than scaling Web data, which even degrades performance sometimes. Through a deeper investigation of X-VLM, we highlight the importance of both novel losses and rich data sources for learning fine-grained skills. Finally, we inspect training dynamics, and discover that for some tasks, performance peaks early in training or significantly fluctuates, never converging.", "authors": [{"author": {"author_id": "a350c4f2bf429c21a662613bd1dc93d7", "name": "Emanuele Bugliarello", "links": [{"type": "semantic_scholar", "link": "83574123"}]}, "affiliations": [{"institution_id": "73381f2809c7ca1e6b90f27bd3309e85", "name": "DeepMind", "category": "unknown"}, {"institution_id": "78068fb52abd9c5b184536a635e74387", "name": "University of Copenhagen", "category": "unknown"}]}, {"author": {"author_id": "87c1189a19cedd37219aced4c7885352", "name": "Laurent Sartran", "links": [{"type": "semantic_scholar", "link": "2247711824"}]}, "affiliations": [{"institution_id": "73381f2809c7ca1e6b90f27bd3309e85", "name": "DeepMind", "category": "unknown"}]}, {"author": {"author_id": "8d03287b9ec960332f5641912cd95e56", "name": "Aishwarya Agrawal", "links": [{"type": "bio", "link": "aishwarya-agrawal"}, {"type": "email.mila", "link": "aishwarya.agrawal@mila.quebec"}, {"type": "mag", "link": "2117267436"}, {"type": "openreview", "link": "~Aishwarya_Agrawal1"}, {"type": "semantic_scholar", "link": "2293394830"}, {"type": "semantic_scholar", "link": "2801949"}, {"type": "wpid_en", "link": "38508"}, {"type": "wpid_fr", "link": "38504"}, {"type": "xplore", "link": "37085397548"}, {"type": "xplore", "link": "37085742308"}, {"type": "xplore", "link": "37087883810"}]}, "affiliations": [{"institution_id": "73381f2809c7ca1e6b90f27bd3309e85", "name": "DeepMind", "category": "unknown"}]}, {"author": {"author_id": "af00f4bd2030a19d355726792b2aef9d", "name": "Lisa Anne Hendricks", "links": [{"type": "semantic_scholar", "link": "2234342"}, {"type": "semantic_scholar", "link": "2258347245"}]}, "affiliations": [{"institution_id": "73381f2809c7ca1e6b90f27bd3309e85", "name": "DeepMind", "category": "unknown"}]}, {"author": {"author_id": "9bee6a15036e4785b5f52f237bf48661", "name": "Aida Nematzadeh", "links": [{"type": "semantic_scholar", "link": "3208081"}]}, "affiliations": [{"institution_id": "73381f2809c7ca1e6b90f27bd3309e85", "name": "DeepMind", "category": "unknown"}]}], "releases": [{"venue": {"venue_id": "1eba1c717c9ccd0beea80214ce9b16f1", "name": "ACL (1)", "type": "journal", "date": {"text": "2023", "timestamp": 1672549200, "precision": 1}, "links": [], "publisher": null, "series": "", "volume": null}, "peer_reviewed": true, "status": "published", "pages": "1559-1582"}], "topics": [{"name": "Computer Science"}], "links": [{"type": "doi.abstract", "link": "10.18653/v1/2023.acl-long.87", "url": "https://doi.org/10.18653/v1/2023.acl-long.87"}, {"type": "doi.abstract", "link": "10.48550/arXiv.2305.07558", "url": "https://doi.org/10.48550/arXiv.2305.07558"}, {"type": "arxiv.abstract", "link": "2305.07558", "url": "https://arxiv.org/abs/2305.07558"}, {"type": "arxiv.pdf", "link": "2305.07558", "url": "https://arxiv.org/pdf/2305.07558.pdf"}, {"type": "dblp.abstract", "link": "conf/acl/BugliarelloSAHN23", "url": "https://dblp.uni-trier.de/rec/conf/acl/BugliarelloSAHN23"}, {"type": "pdf", "link": "http://export.arxiv.org/pdf/2305.07558"}, {"type": "semantic_scholar.abstract", "link": "65051f6836a4a618586c01deff43b46ab5e3f887", "url": "https://www.semanticscholar.org/paper/65051f6836a4a618586c01deff43b46ab5e3f887"}, {"type": "corpusid", "link": "258676204"}, {"type": "acl", "link": "2023.acl-long.87"}], "flags": [{"name": "validation", "value": 1}], "validated": true, "citation_count": 0, "excerpt": null}, {"paper_id": "92cb7282c530ec3fc0e7391040677811", "title": "Vision-Language Pretraining: Current Trends and the Future", "abstract": "In the last few years, there has been an increased interest in building multimodal (vision-language) models that are pretrained on larger but noisier datasets where the two modalities (e.g., image and text) loosely correspond to each other (e.g., Lu et al., 2019; Radford et al., 2021). Given a task (such as visual question answering), these models are then often fine-tuned on task-specific supervised datasets. (e.g., Lu et al., 2019; Chen et al.,2020; Tan and Bansal, 2019; Li et al., 2020a,b). In addition to the larger pretraining datasets, the transformer architecture (Vaswani et al., 2017) and in particular self-attention applied to two modalities are responsible for the impressive performance of the recent pretrained models on downstream tasks (Hendricks et al., 2021). In this tutorial, we focus on recent vision-language pretraining paradigms. Our goal is to first provide the background on image\u2013language datasets, benchmarks, and modeling innovations before the multimodal pretraining area. Next we discuss the different family of models used for vision-language pretraining, highlighting their strengths and shortcomings. Finally, we discuss the limits of vision-language pretraining through statistical learning, and the need for alternative approaches such as causal representation learning.", "authors": [{"author": {"author_id": "8d03287b9ec960332f5641912cd95e56", "name": "Aishwarya Agrawal", "links": [{"type": "bio", "link": "aishwarya-agrawal"}, {"type": "email.mila", "link": "aishwarya.agrawal@mila.quebec"}, {"type": "mag", "link": "2117267436"}, {"type": "openreview", "link": "~Aishwarya_Agrawal1"}, {"type": "semantic_scholar", "link": "2293394830"}, {"type": "semantic_scholar", "link": "2801949"}, {"type": "wpid_en", "link": "38508"}, {"type": "wpid_fr", "link": "38504"}, {"type": "xplore", "link": "37085397548"}, {"type": "xplore", "link": "37085742308"}, {"type": "xplore", "link": "37087883810"}]}, "affiliations": [{"institution_id": "28e9e3e07d018dc25de1f00cbc5087eb", "name": "University of Montreal", "category": "unknown"}, {"institution_id": "73381f2809c7ca1e6b90f27bd3309e85", "name": "DeepMind", "category": "unknown"}, {"institution_id": "78a83265183550c66a78ff9b5f9b960f", "name": "Mila", "category": "unknown"}]}, {"author": {"author_id": "d7c736b285a9d8cec546edcefafd4726", "name": "Damien Teney", "links": [{"type": "semantic_scholar", "link": "2253463627"}, {"type": "semantic_scholar", "link": "2406263"}]}, "affiliations": []}, {"author": {"author_id": "9bee6a15036e4785b5f52f237bf48661", "name": "Aida Nematzadeh", "links": [{"type": "semantic_scholar", "link": "3208081"}]}, "affiliations": [{"institution_id": "73381f2809c7ca1e6b90f27bd3309e85", "name": "DeepMind", "category": "unknown"}]}], "releases": [{"venue": {"venue_id": "46c62d534f8448a7a81a26c459c32e4f", "name": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Tutorial Abstracts", "type": "conference", "date": {"text": "2022-05", "timestamp": 1651377600, "precision": 2}, "links": [], "publisher": null, "series": "", "volume": null}, "peer_reviewed": true, "status": "published", "pages": null}], "topics": [{"name": "Computer Science"}], "links": [{"type": "doi.abstract", "link": "10.18653/v1/2022.acl-tutorials.7", "url": "https://doi.org/10.18653/v1/2022.acl-tutorials.7"}, {"type": "dblp.abstract", "link": "conf/acl/AgrawalTN22", "url": "https://dblp.uni-trier.de/rec/conf/acl/AgrawalTN22"}, {"type": "pdf", "link": "https://aclanthology.org/2022.acl-tutorials.7.pdf"}, {"type": "semantic_scholar.abstract", "link": "21f27a2528345c09a812406cc441ee84a967873a", "url": "https://www.semanticscholar.org/paper/21f27a2528345c09a812406cc441ee84a967873a"}, {"type": "corpusid", "link": "248780422"}, {"type": "acl", "link": "2022.acl-tutorials.7"}], "flags": [{"name": "validation", "value": 1}], "validated": true, "citation_count": 0, "excerpt": null}]
