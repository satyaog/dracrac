[{"paper_id": "961c18cd47d6cdaff853a7d0334d37dd", "title": "Mechanistically analyzing the effects of fine-tuning on procedurally defined tasks", "abstract": "Fine-tuning large pre-trained models has become the de facto strategy for developing both task-specific and general-purpose machine learning systems, including developing models that are safe to deploy. Despite its clear importance, there has been minimal work that explains how fine-tuning alters the underlying capabilities learned by a model during pretraining: does fine-tuning yield entirely novel capabilities or does it just modulate existing ones? We address this question empirically in synthetic, controlled settings where we can use mechanistic interpretability tools (e.g., network pruning and probing) to understand how the model's underlying capabilities are changing. We perform an extensive analysis of the effects of fine-tuning in these settings, and show that: (i) fine-tuning rarely alters the underlying model capabilities; (ii) a minimal transformation, which we call a `wrapper', is typically learned on top of the underlying model capabilities, creating the illusion that they have been modified; and (iii) further fine-tuning on a task where such ``wrapped capabilities'' are relevant leads to sample-efficient revival of the capability, i.e., the model begins reusing these capabilities after only a few gradient steps. This indicates that practitioners can unintentionally remove a model's safety wrapper merely by fine-tuning it on a, e.g., superficially unrelated, downstream task. We additionally perform analysis on language models trained on the TinyStories dataset to support our claims in a more realistic setup.", "authors": [{"author": {"author_id": "9906d51622c9be2622d89a3ef51e6614", "name": "Samyak Jain", "links": [{"type": "openreview", "link": "~Samyak_Jain1"}]}, "affiliations": [{"institution_id": "540adc9c88476c96efe5187902e9dd40", "name": "University of Cambridge", "category": "unknown"}, {"institution_id": "5de6c7f2815d5f3a3fa1ab89353e6ec7", "name": "University of Cambridge, UK", "category": "unknown"}]}, {"author": {"author_id": "acb18c371edd1dad0e585f1ecb702e7a", "name": "Robert Kirk", "links": [{"type": "openreview", "link": "~Robert_Kirk1"}, {"type": "semantic_scholar", "link": "2066422293"}]}, "affiliations": [{"institution_id": "3b4ff6e95acc37bccc795e43d486bd56", "name": "University College London", "category": "unknown"}]}, {"author": {"author_id": "8eb9a883f9ba96dd7d5c96ba88806826", "name": "Ekdeep Singh Lubana", "links": [{"type": "openreview", "link": "~Ekdeep_Singh_Lubana1"}, {"type": "semantic_scholar", "link": "35573359"}]}, "affiliations": [{"institution_id": "37d506ef133b384a32a99777a47a44d1", "name": "Harvard University", "category": "unknown"}, {"institution_id": "3d041ce8296f4cea6a3aa7c7eead7120", "name": "USA", "category": "unknown"}, {"institution_id": "79e20f6a0caeec471047999d88249254", "name": "University of Michigan", "category": "unknown"}]}, {"author": {"author_id": "c9f57159609cbd8d792899a4d0495658", "name": "Robert P. Dick", "links": [{"type": "openreview", "link": "~Robert_P._Dick1"}, {"type": "semantic_scholar", "link": "1792688"}]}, "affiliations": []}, {"author": {"author_id": "89c26bf67a91994082aa55fe713fe099", "name": "Hidenori Tanaka", "links": [{"type": "openreview", "link": "~Hidenori_Tanaka1"}, {"type": "semantic_scholar", "link": "1912151014"}]}, "affiliations": [{"institution_id": "37d506ef133b384a32a99777a47a44d1", "name": "Harvard University", "category": "unknown"}, {"institution_id": "3d041ce8296f4cea6a3aa7c7eead7120", "name": "USA", "category": "unknown"}]}, {"author": {"author_id": "c88cc2a00287228641975ae92a03fc99", "name": "Tim Rockt\u00e4schel", "links": [{"type": "openreview", "link": "~Tim_Rockt\u00e4schel1"}, {"type": "semantic_scholar", "link": "2620211"}]}, "affiliations": [{"institution_id": "3b4ff6e95acc37bccc795e43d486bd56", "name": "University College London", "category": "unknown"}]}, {"author": {"author_id": "bf4da4aa2d3ee2b94e7a0248623eb06e", "name": "Edward Grefenstette", "links": [{"type": "openreview", "link": "~Edward_Grefenstette1"}, {"type": "semantic_scholar", "link": "1864353"}]}, "affiliations": [{"institution_id": "3b4ff6e95acc37bccc795e43d486bd56", "name": "University College London", "category": "unknown"}]}, {"author": {"author_id": "d695025f8d7c4f21c27c0112916f2620", "name": "David Krueger", "links": [{"type": "!semantic_scholar", "link": "145256150"}, {"type": "!semantic_scholar", "link": "34936272"}, {"type": "!semantic_scholar", "link": "39436992"}, {"type": "bio", "link": "david-krueger"}, {"type": "email.mila", "link": "kruegerd@mila.quebec"}, {"type": "mag", "link": "2339291198"}, {"type": "openreview", "link": "~David_Krueger1"}, {"type": "semantic_scholar", "link": "122753372"}, {"type": "semantic_scholar", "link": "145055042"}, {"type": "semantic_scholar", "link": "1477322821"}, {"type": "semantic_scholar", "link": "2261364224"}, {"type": "semantic_scholar", "link": "2262214707"}, {"type": "semantic_scholar", "link": "2276204785"}, {"type": "semantic_scholar", "link": "2286169334"}, {"type": "semantic_scholar", "link": "2290019332"}, {"type": "semantic_scholar", "link": "2291961659"}]}, "affiliations": [{"institution_id": "540adc9c88476c96efe5187902e9dd40", "name": "University of Cambridge", "category": "unknown"}, {"institution_id": "5de6c7f2815d5f3a3fa1ab89353e6ec7", "name": "University of Cambridge, UK", "category": "unknown"}]}], "releases": [{"venue": {"venue_id": "0d655f6117b6a827c084765ed1785481", "name": "ICLR.cc/2024/Conference", "type": "conference", "date": {"text": "2024-01-16", "timestamp": 1705381200, "precision": 3}, "links": [{"type": "openreview-venue", "link": "ICLR.cc/2024/Conference"}], "publisher": null, "series": "", "volume": "ICLR 2024"}, "peer_reviewed": true, "status": "poster", "pages": null}], "topics": [{"name": "Interpretability"}, {"name": "fine-tuning"}, {"name": "mechanistic interpretability"}, {"name": "Fine-Tuning"}, {"name": "Mechanisms"}], "links": [{"type": "openreview.abstract", "link": "A0HKeKl4Nl", "url": "https://openreview.net/forum?id=A0HKeKl4Nl"}, {"type": "openreview.abstract", "link": "bWimc91mtK", "url": "https://openreview.net/forum?id=bWimc91mtK"}, {"type": "openreview.abstract", "link": "gQmxnNpFJ5", "url": "https://openreview.net/forum?id=gQmxnNpFJ5"}, {"type": "openreview.pdf", "link": "A0HKeKl4Nl", "url": "https://openreview.net/pdf?id=A0HKeKl4Nl"}, {"type": "openreview.pdf", "link": "bWimc91mtK", "url": "https://openreview.net/pdf?id=bWimc91mtK"}, {"type": "openreview.pdf", "link": "gQmxnNpFJ5", "url": "https://openreview.net/pdf?id=gQmxnNpFJ5"}], "flags": [{"name": "validation", "value": 1}], "validated": true, "citation_count": 0, "excerpt": null}, {"paper_id": "b5b434705259dcd12efa656c3ff28363", "title": "Reward Model Ensembles Help Mitigate Overoptimization", "abstract": "Reinforcement learning from human feedback (RLHF) is a standard approach for fine-tuning large language models to follow instructions. As part of this process, learned reward models are used to approximately model human preferences. However, as imperfect representations of the \u201ctrue\u201d reward, these learned reward models are susceptible to overoptimization. Gao et al. (2023) studied this phenomenon in a synthetic human feedback setup with a significantly larger \u201cgold\u201d reward model acting as the true reward (instead of humans) and showed that overoptimization remains a persistent problem regardless of the size of the proxy reward model and training data used. Using a similar setup, we conduct a systematic study to evaluate the efficacy of using ensemble-based conservative optimization objectives, specifically worst-case optimization (WCO) and uncertainty-weighted optimization (UWO), for mitigating reward model overoptimization when using two optimization methods: (a) best-of-n sampling (BoN) (b) proximal policy optimization (PPO). We additionally extend the setup of Gao et al. (2023) to include 25% label noise to better mirror real-world conditions. Both with and without label noise we find that conservative optimization practically eliminates overoptimization and improves performance by up to 70% for BoN sampling. For PPO, ensemble-based conservative optimization always reduces overoptimization and outperforms single reward model optimization. Moreover, combining it with a small KL penalty successfully prevents overoptimization at no performance cost. Overall, our results demonstrate that ensemble-based conservative optimization can effectively counter overoptimization.", "authors": [{"author": {"author_id": "8dee17e5ab01ad4c479e3721bcbe7833", "name": "Thomas Coste", "links": [{"type": "openreview", "link": "~Thomas_Coste1"}]}, "affiliations": [{"institution_id": "5077bf2804a2f43554900c002fc5b5a0", "name": "2 University College London", "category": "academia"}, {"institution_id": "53de71e35e139ccbf5a68ef65244ae25", "name": "1 University of Cambridge, 2 University College London", "category": "academia"}]}, {"author": {"author_id": "b73038bacb93df18dc2bd08163b34a7f", "name": "Usman Anwar", "links": [{"type": "openreview", "link": "~Usman_Anwar1"}, {"type": "semantic_scholar", "link": "2066185365"}, {"type": "semantic_scholar", "link": "2296716792"}]}, "affiliations": [{"institution_id": "5077bf2804a2f43554900c002fc5b5a0", "name": "2 University College London", "category": "academia"}, {"institution_id": "53de71e35e139ccbf5a68ef65244ae25", "name": "1 University of Cambridge, 2 University College London", "category": "academia"}]}, {"author": {"author_id": "acb18c371edd1dad0e585f1ecb702e7a", "name": "Robert Kirk", "links": [{"type": "openreview", "link": "~Robert_Kirk1"}, {"type": "semantic_scholar", "link": "2066422293"}]}, "affiliations": [{"institution_id": "5077bf2804a2f43554900c002fc5b5a0", "name": "2 University College London", "category": "academia"}, {"institution_id": "53de71e35e139ccbf5a68ef65244ae25", "name": "1 University of Cambridge, 2 University College London", "category": "academia"}]}, {"author": {"author_id": "d695025f8d7c4f21c27c0112916f2620", "name": "David Krueger", "links": [{"type": "!semantic_scholar", "link": "145256150"}, {"type": "!semantic_scholar", "link": "34936272"}, {"type": "!semantic_scholar", "link": "39436992"}, {"type": "bio", "link": "david-krueger"}, {"type": "email.mila", "link": "kruegerd@mila.quebec"}, {"type": "mag", "link": "2339291198"}, {"type": "openreview", "link": "~David_Krueger1"}, {"type": "semantic_scholar", "link": "122753372"}, {"type": "semantic_scholar", "link": "145055042"}, {"type": "semantic_scholar", "link": "1477322821"}, {"type": "semantic_scholar", "link": "2261364224"}, {"type": "semantic_scholar", "link": "2262214707"}, {"type": "semantic_scholar", "link": "2276204785"}, {"type": "semantic_scholar", "link": "2286169334"}, {"type": "semantic_scholar", "link": "2290019332"}, {"type": "semantic_scholar", "link": "2291961659"}]}, "affiliations": [{"institution_id": "5077bf2804a2f43554900c002fc5b5a0", "name": "2 University College London", "category": "academia"}, {"institution_id": "53de71e35e139ccbf5a68ef65244ae25", "name": "1 University of Cambridge, 2 University College London", "category": "academia"}]}], "releases": [{"venue": {"venue_id": "0d655f6117b6a827c084765ed1785481", "name": "ICLR.cc/2024/Conference", "type": "conference", "date": {"text": "2024-01-16", "timestamp": 1705381200, "precision": 3}, "links": [{"type": "openreview-venue", "link": "ICLR.cc/2024/Conference"}], "publisher": null, "series": "", "volume": "ICLR 2024"}, "peer_reviewed": true, "status": "poster", "pages": null}], "topics": [{"name": "RLHF"}, {"name": "overoptimization"}, {"name": "uncertainty weighted optimization"}, {"name": "language models"}, {"name": "reinforcement learning from human feedback"}, {"name": "ensembles"}], "links": [{"type": "openreview.abstract", "link": "NiQYQEPUsA", "url": "https://openreview.net/forum?id=NiQYQEPUsA"}, {"type": "openreview.abstract", "link": "TXFqUx8aA8", "url": "https://openreview.net/forum?id=TXFqUx8aA8"}, {"type": "openreview.abstract", "link": "dcjtMYkpXx", "url": "https://openreview.net/forum?id=dcjtMYkpXx"}, {"type": "openreview.pdf", "link": "NiQYQEPUsA", "url": "https://openreview.net/pdf?id=NiQYQEPUsA"}, {"type": "openreview.pdf", "link": "TXFqUx8aA8", "url": "https://openreview.net/pdf?id=TXFqUx8aA8"}, {"type": "openreview.pdf", "link": "dcjtMYkpXx", "url": "https://openreview.net/pdf?id=dcjtMYkpXx"}], "flags": [{"name": "validation", "value": 1}], "validated": true, "citation_count": 0, "excerpt": null}]
