[{"paper_id": "b3d294cb12fe80be23c75241e1de9e84", "title": "Consciousness-Inspired Spatio-Temporal Abstractions for Better Generalization in Reinforcement Learning", "abstract": "Inspired by human conscious planning, we propose Skipper, a model-based reinforcement learning framework utilizing spatio-temporal abstractions to generalize better in novel situations. It automatically decomposes the given task into smaller, more manageable subtasks, and thus enables sparse decision-making and focused computation on the relevant parts of the environment. The decomposition relies on the extraction of an abstracted proxy problem represented as a directed graph, in which vertices and edges are learned end-to-end from hindsight. Our theoretical analyses provide performance guarantees under appropriate assumptions and establish where our approach is expected to be helpful. Generalization-focused experiments validate Skipper\u2019s significant advantage in zero-shot generalization, compared to some existing state-of-the-art hierarchical planning methods.", "authors": [{"author": {"author_id": "11c0ab0da7cf766ab0165a56061a7779", "name": "Harry Zhao", "links": [{"type": "openreview", "link": "~Harry_Zhao1"}]}, "affiliations": []}, {"author": {"author_id": "79bafc11d8722d25600d90d50edaa293", "name": "Harry Zhao 0001", "links": []}, "affiliations": []}, {"author": {"author_id": "f382686a2bbe207ce0c3967d51bab142", "name": "Mingde Zhao", "links": [{"type": "openreview", "link": "~Mingde_Zhao1"}, {"type": "semantic_scholar", "link": "145327825"}, {"type": "semantic_scholar", "link": "2152527029"}, {"type": "semantic_scholar", "link": "2250172769"}]}, "affiliations": [{"institution_id": "1738899f40b882ede0540c6f87c0cc7a", "name": "2 Universit\u00e9 de Montr\u00e9al", "category": "academia"}]}, {"author": {"author_id": "e0cb96a2f52fc5ba512944984b23b671", "name": "Safa Alver", "links": [{"type": "openreview", "link": "~Safa_Alver1"}, {"type": "semantic_scholar", "link": "1388019189"}]}, "affiliations": [{"institution_id": "1738899f40b882ede0540c6f87c0cc7a", "name": "2 Universit\u00e9 de Montr\u00e9al", "category": "academia"}]}, {"author": {"author_id": "a657d6988846fb65d7b93761d21a9887", "name": "Harm van Seijen", "links": [{"type": "openreview", "link": "~Harm_van_Seijen1"}, {"type": "semantic_scholar", "link": "1748153"}]}, "affiliations": [{"institution_id": "1738899f40b882ede0540c6f87c0cc7a", "name": "2 Universit\u00e9 de Montr\u00e9al", "category": "academia"}]}, {"author": {"author_id": "b0cc6f0dcc08341aa8adf0cdb67dd41d", "name": "Romain Laroche", "links": [{"type": "openreview", "link": "~Romain_Laroche1"}, {"type": "semantic_scholar", "link": "144100820"}, {"type": "semantic_scholar", "link": "2249763343"}, {"type": "semantic_scholar", "link": "2267394381"}]}, "affiliations": [{"institution_id": "1738899f40b882ede0540c6f87c0cc7a", "name": "2 Universit\u00e9 de Montr\u00e9al", "category": "academia"}]}, {"author": {"author_id": "f0f6549152ff58dde589fae483ae061b", "name": "Doina Precup", "links": [{"type": "!semantic_scholar", "link": "115325970"}, {"type": "bio", "link": "doina-precup"}, {"type": "email.mila", "link": "precupdo@mila.quebec"}, {"type": "mag", "link": "2049838"}, {"type": "mag", "link": "2584303792"}, {"type": "mag", "link": "2763943850"}, {"type": "mag", "link": "2789843807"}, {"type": "mag", "link": "2792787841"}, {"type": "mag", "link": "2965467369"}, {"type": "mag", "link": "3010809802"}, {"type": "mag", "link": "3011193713"}, {"type": "mag", "link": "3189931171"}, {"type": "openreview", "link": "~Doina_Precup1"}, {"type": "semantic_scholar", "link": "144368601"}, {"type": "semantic_scholar", "link": "2249762747"}, {"type": "wpid_en", "link": "26106"}, {"type": "wpid_fr", "link": "26116"}, {"type": "xplore", "link": "37284893100"}]}, "affiliations": [{"institution_id": "1738899f40b882ede0540c6f87c0cc7a", "name": "2 Universit\u00e9 de Montr\u00e9al", "category": "academia"}]}, {"author": {"author_id": "fd676bfd2d2cc8ea03ecb12bb22bcd30", "name": "Yoshua Bengio", "links": [{"type": "bio", "link": "bengio-yoshua"}, {"type": "email.mila", "link": "yoshua.bengio@mila.quebec"}, {"type": "mag", "link": "161269817"}, {"type": "mag", "link": "2550477701"}, {"type": "mag", "link": "2762122187"}, {"type": "mag", "link": "2969309771"}, {"type": "mag", "link": "3049675594"}, {"type": "openreview", "link": "~Yoshua_Bengio1"}, {"type": "semantic_scholar", "link": "1751762"}, {"type": "semantic_scholar", "link": "1865800402"}, {"type": "semantic_scholar", "link": "2211024206"}, {"type": "semantic_scholar", "link": "2285114502"}, {"type": "wpid_en", "link": "348"}, {"type": "wpid_fr", "link": "96"}, {"type": "xplore", "link": "37089048258"}, {"type": "xplore", "link": "37089315098"}, {"type": "xplore", "link": "37323338000"}]}, "affiliations": [{"institution_id": "1738899f40b882ede0540c6f87c0cc7a", "name": "2 Universit\u00e9 de Montr\u00e9al", "category": "academia"}]}], "releases": [{"venue": {"venue_id": "0d655f6117b6a827c084765ed1785481", "name": "ICLR.cc/2024/Conference", "type": "conference", "date": {"text": "2024-01-16", "timestamp": 1705381200, "precision": 3}, "links": [{"type": "openreview-venue", "link": "ICLR.cc/2024/Conference"}], "publisher": null, "series": "", "volume": "ICLR 2024"}, "peer_reviewed": true, "status": "poster", "pages": null}, {"venue": {"venue_id": "6b00fec8c0d7598bda0e96167eaabbc1", "name": "ICLR", "type": "journal", "date": {"text": "2024", "timestamp": 1704085200, "precision": 1}, "links": [], "publisher": null, "series": "", "volume": null}, "peer_reviewed": true, "status": "published", "pages": null}], "topics": [{"name": "Temporal Difference Learning"}, {"name": "Generalization"}, {"name": "Computer Science"}, {"name": "Reinforcement Learning"}, {"name": "Deep Reinforcement Learning"}, {"name": "Neural Networks"}, {"name": "Planning"}], "links": [{"type": "openreview.abstract", "link": "eo9dHwtTFt", "url": "https://openreview.net/forum?id=eo9dHwtTFt"}, {"type": "openreview.pdf", "link": "eo9dHwtTFt", "url": "https://openreview.net/pdf?id=eo9dHwtTFt"}, {"type": "arxiv.abstract", "link": "2310.00229", "url": "https://arxiv.org/abs/2310.00229"}, {"type": "arxiv.pdf", "link": "2310.00229", "url": "https://arxiv.org/pdf/2310.00229.pdf"}, {"type": "dblp.abstract", "link": "conf/iclr/0001ASLPB24", "url": "https://dblp.uni-trier.de/rec/conf/iclr/0001ASLPB24"}, {"type": "html", "link": "https://openreview.net/forum?id=eo9dHwtTFt"}, {"type": "semantic_scholar.abstract", "link": "70b9e6d069c082c497ddaba2de0042a034da7547", "url": "https://www.semanticscholar.org/paper/70b9e6d069c082c497ddaba2de0042a034da7547"}, {"type": "corpusid", "link": "268513228"}], "flags": [{"name": "validation", "value": 1}], "validated": true, "citation_count": 0, "excerpt": null}, {"paper_id": "99e8b3a9303a437c88ca484af96a680a", "title": "Provable and Practical: Efficient Exploration in Reinforcement Learning via Langevin Monte Carlo", "abstract": "We present a scalable and effective exploration strategy based on Thompson sampling for reinforcement learning (RL). One of the key shortcomings of  existing Thompson sampling algorithms is the need to perform a Gaussian approximation of the posterior distribution, which is not a good surrogate in most practical settings. We instead directly sample the Q function from its posterior distribution, by using  Langevin Monte Carlo, an efficient type of Markov Chain Monte Carlo (MCMC) method. Our method only needs to perform noisy gradient descent updates to learn the exact posterior distribution of the Q function, which makes our approach easy to deploy in deep RL.  We provide a rigorous theoretical analysis for the proposed method and demonstrate that, in the linear Markov decision process (linear MDP) setting, it has a regret bound of $\\tilde{O}(d^{3/2}H^{5/2}\\sqrt{T})$, where $d$ is the dimension of the feature mapping, $H$ is the planning horizon, and $T$ is the total number of steps. We apply this approach to deep RL, by using Adam optimizer to perform gradient updates. Our approach achieves better or similar results compared with state-of-the-art deep RL algorithms on several challenging exploration tasks from the Atari57 suite.", "authors": [{"author": {"author_id": "c3548d9c591ad3df780f16c09544422f", "name": "Haque Ishfaq", "links": [{"type": "openreview", "link": "~Haque_Ishfaq1"}, {"type": "semantic_scholar", "link": "35652168"}]}, "affiliations": [{"institution_id": "2d64978822ccf8676fd9f98e10c823c2", "name": "McGill University", "category": "unknown"}, {"institution_id": "36a99ea79f6c22565c31d067a1843ca9", "name": "Mila, McGill University", "category": "unknown"}, {"institution_id": "78a83265183550c66a78ff9b5f9b960f", "name": "Mila", "category": "unknown"}]}, {"author": {"author_id": "d4c151c4c8e5b06d4af720f2131007cc", "name": "Qingfeng Lan", "links": [{"type": "openreview", "link": "~Qingfeng_Lan1"}, {"type": "semantic_scholar", "link": "51305487"}]}, "affiliations": [{"institution_id": "32ebbff97ac1c3f9ffcadc4544b53f9e", "name": "University of Alberta", "category": "unknown"}]}, {"author": {"author_id": "89da57781bca0528ba8a7f09e73c760c", "name": "Pan Xu", "links": [{"type": "openreview", "link": "~Pan_Xu1"}, {"type": "semantic_scholar", "link": "145612639"}, {"type": "semantic_scholar", "link": "2307405854"}]}, "affiliations": [{"institution_id": "4bcf90958096fa9e0435ea6059a7e306", "name": "Duke University", "category": "unknown"}]}, {"author": {"author_id": "b3d45ae47a39f92d73c5cd0efb4b4653", "name": "A. Rupam Mahmood", "links": [{"type": "openreview", "link": "~A._Rupam_Mahmood1"}, {"type": "semantic_scholar", "link": "1759633"}, {"type": "semantic_scholar", "link": "2253402755"}]}, "affiliations": [{"institution_id": "32ebbff97ac1c3f9ffcadc4544b53f9e", "name": "University of Alberta", "category": "unknown"}]}, {"author": {"author_id": "f0f6549152ff58dde589fae483ae061b", "name": "Doina Precup", "links": [{"type": "!semantic_scholar", "link": "115325970"}, {"type": "bio", "link": "doina-precup"}, {"type": "email.mila", "link": "precupdo@mila.quebec"}, {"type": "mag", "link": "2049838"}, {"type": "mag", "link": "2584303792"}, {"type": "mag", "link": "2763943850"}, {"type": "mag", "link": "2789843807"}, {"type": "mag", "link": "2792787841"}, {"type": "mag", "link": "2965467369"}, {"type": "mag", "link": "3010809802"}, {"type": "mag", "link": "3011193713"}, {"type": "mag", "link": "3189931171"}, {"type": "openreview", "link": "~Doina_Precup1"}, {"type": "semantic_scholar", "link": "144368601"}, {"type": "semantic_scholar", "link": "2249762747"}, {"type": "wpid_en", "link": "26106"}, {"type": "wpid_fr", "link": "26116"}, {"type": "xplore", "link": "37284893100"}]}, "affiliations": [{"institution_id": "0711161da2c891f5c83cdf6ef78daa9b", "name": "Google DeepMind", "category": "industry"}, {"institution_id": "2d64978822ccf8676fd9f98e10c823c2", "name": "McGill University", "category": "unknown"}, {"institution_id": "36a99ea79f6c22565c31d067a1843ca9", "name": "Mila, McGill University", "category": "unknown"}, {"institution_id": "78a83265183550c66a78ff9b5f9b960f", "name": "Mila", "category": "unknown"}]}, {"author": {"author_id": "a347f4c1410574202bc2d9016dc27f38", "name": "Animashree Anandkumar", "links": [{"type": "openreview", "link": "~Anima_Anandkumar1"}, {"type": "semantic_scholar", "link": "2047844"}, {"type": "semantic_scholar", "link": "2257161858"}, {"type": "semantic_scholar", "link": "47627049"}, {"type": "xplore", "link": "37322138800"}]}, "affiliations": [{"institution_id": "5cb9af219a25773a7d505f2afc2bff31", "name": "California Institute of Technology", "category": "unknown"}, {"institution_id": "7aeca40768cbb9ffdec81ba2d1557df4", "name": "Nvidia", "category": "unknown"}]}, {"author": {"author_id": "98253fed12143edf5d76e9ab602c12df", "name": "Kamyar Azizzadenesheli", "links": [{"type": "openreview", "link": "~Kamyar_Azizzadenesheli1"}, {"type": "semantic_scholar", "link": "3371922"}]}, "affiliations": [{"institution_id": "7aeca40768cbb9ffdec81ba2d1557df4", "name": "Nvidia", "category": "unknown"}]}], "releases": [{"venue": {"venue_id": "0d655f6117b6a827c084765ed1785481", "name": "ICLR.cc/2024/Conference", "type": "conference", "date": {"text": "2024-01-16", "timestamp": 1705381200, "precision": 3}, "links": [{"type": "openreview-venue", "link": "ICLR.cc/2024/Conference"}], "publisher": null, "series": "", "volume": "ICLR 2024"}, "peer_reviewed": true, "status": "poster", "pages": null}], "topics": [{"name": "Provably Efficient"}, {"name": "Computer Science"}, {"name": "Deep Reinforcement learning"}, {"name": "Exploration"}, {"name": "Reinforcement Learning"}, {"name": "Langevin Monte Carlo"}, {"name": "Thompson Sampling"}], "links": [{"type": "doi.abstract", "link": "10.48550/arXiv.2305.18246", "url": "https://doi.org/10.48550/arXiv.2305.18246"}, {"type": "openreview.abstract", "link": "6u1z0RH6u1", "url": "https://openreview.net/forum?id=6u1z0RH6u1"}, {"type": "openreview.abstract", "link": "nfIAEJFiBZ", "url": "https://openreview.net/forum?id=nfIAEJFiBZ"}, {"type": "openreview.pdf", "link": "6u1z0RH6u1", "url": "https://openreview.net/pdf?id=6u1z0RH6u1"}, {"type": "openreview.pdf", "link": "nfIAEJFiBZ", "url": "https://openreview.net/pdf?id=nfIAEJFiBZ"}, {"type": "arxiv.abstract", "link": "2305.18246", "url": "https://arxiv.org/abs/2305.18246"}, {"type": "arxiv.pdf", "link": "2305.18246", "url": "https://arxiv.org/pdf/2305.18246.pdf"}, {"type": "dblp.abstract", "link": "journals/corr/abs-2305-18246", "url": "https://dblp.uni-trier.de/rec/journals/corr/abs-2305-18246"}, {"type": "pdf", "link": "http://export.arxiv.org/pdf/2305.18246"}, {"type": "semantic_scholar.abstract", "link": "c90aa0f206c6fd41c490c142f63f7ba046cae6b7", "url": "https://www.semanticscholar.org/paper/c90aa0f206c6fd41c490c142f63f7ba046cae6b7"}, {"type": "corpusid", "link": "258959015"}], "flags": [{"name": "validation", "value": 1}], "validated": true, "citation_count": 0, "excerpt": null}]
