[{"paper_id": "dd747c83d75a00a0733d75304fab4b3a", "title": "Contrasting Intra-Modal and Ranking Cross-Modal Hard Negatives to Enhance Visio-Linguistic Compositional Understanding", "abstract": "Vision-Language Models (VLMs), such as CLIP, exhibit strong image-text comprehension abilities, facilitating advances in several downstream tasks such as zero-shot image classification, image-text retrieval, and text-to-image generation. However, the compositional reasoning abilities of existing VLMs remains subpar. The root of this limitation lies in the inadequate alignment between the images and captions in the pretraining datasets. Additionally, the current contrastive learning objective fails to focus on fine-grained grounding components like relations, actions, and attributes, resulting in\"bag-of-words\"representations. We introduce a simple and effective method to improve compositional reasoning in VLMs. Our method better leverages available datasets by refining and expanding the standard image-text contrastive learning framework. Our approach does not require specific annotations and does not incur extra parameters. When integrated with CLIP, our technique yields notable improvement over state-of-the-art baselines across five vision-language compositional benchmarks. We open-source our code at https://github.com/lezhang7/Enhance-FineGrained.", "authors": [{"author": {"author_id": "b30549d291d50cc35e210ecaabbcafed", "name": "Le Zhang", "links": [{"type": "openreview", "link": "~Le_Zhang6"}, {"type": "semantic_scholar", "link": "2108005316"}, {"type": "semantic_scholar", "link": "2119685417"}, {"type": "xplore", "link": "924350237007911"}]}, "affiliations": [{"institution_id": "200bed81461cad607d593360fe5fcc0a", "name": "Universit\u00e9 de Montr\u00e9al", "category": "unknown"}, {"institution_id": "2e7644e4488777eb735a190201699cd0", "name": "Mila - Quebec AI Institute", "category": "unknown"}]}, {"author": {"author_id": "89ad0b796b9cf0d8f6f4bc86305989d7", "name": "Rabiul Awal", "links": [{"type": "semantic_scholar", "link": "66736108"}, {"type": "xplore", "link": "37089703671"}]}, "affiliations": [{"institution_id": "200bed81461cad607d593360fe5fcc0a", "name": "Universit\u00e9 de Montr\u00e9al", "category": "unknown"}, {"institution_id": "2e7644e4488777eb735a190201699cd0", "name": "Mila - Quebec AI Institute", "category": "unknown"}]}, {"author": {"author_id": "8d03287b9ec960332f5641912cd95e56", "name": "Aishwarya Agrawal", "links": [{"type": "bio", "link": "aishwarya-agrawal"}, {"type": "email.mila", "link": "aishwarya.agrawal@mila.quebec"}, {"type": "mag", "link": "2117267436"}, {"type": "openreview", "link": "~Aishwarya_Agrawal1"}, {"type": "semantic_scholar", "link": "2293394830"}, {"type": "semantic_scholar", "link": "2801949"}, {"type": "wpid_en", "link": "38508"}, {"type": "wpid_fr", "link": "38504"}, {"type": "xplore", "link": "37085397548"}, {"type": "xplore", "link": "37085742308"}, {"type": "xplore", "link": "37087883810"}]}, "affiliations": [{"institution_id": "200bed81461cad607d593360fe5fcc0a", "name": "Universit\u00e9 de Montr\u00e9al", "category": "unknown"}, {"institution_id": "2e7644e4488777eb735a190201699cd0", "name": "Mila - Quebec AI Institute", "category": "unknown"}]}], "releases": [{"venue": {"venue_id": "67289e6c8c6151e2d53cf4da29397244", "name": "CVPR", "type": "journal", "date": {"text": "2024", "timestamp": 1704085200, "precision": 1}, "links": [], "publisher": null, "series": "", "volume": null}, "peer_reviewed": true, "status": "published", "pages": "13774-13784"}], "topics": [{"name": "Negative Type"}, {"name": "Stable Training"}, {"name": "Segmented Regression"}, {"name": "Bag-of-words Model"}, {"name": "contrastive learning"}, {"name": "Adaptive Threshold"}, {"name": "Progressive Training"}, {"name": "Contrastive Learning"}, {"name": "Computer Science"}, {"name": "Annotations"}, {"name": "Ranking Loss"}, {"name": "Cognition"}, {"name": "Contrast Objective"}, {"name": "Benchmark testing"}, {"name": "Self-supervised Learning"}, {"name": "Scene Graph"}, {"name": "Text to image"}, {"name": "True Pairs"}, {"name": "Contrastive Loss"}, {"name": "Image Classification"}, {"name": "COCO Dataset"}, {"name": "Hinge Loss"}, {"name": "Upper Bound"}, {"name": "Language Model"}, {"name": "Specific Annotation"}, {"name": "Threshold Regression"}, {"name": "compositional understanding"}, {"name": "Curriculum Learning"}, {"name": "Vision-language models"}, {"name": "Image Generation"}, {"name": "Contrastive learning"}, {"name": "Semantics"}, {"name": "Comprehensive Dataset"}, {"name": "Visual Question Answering"}, {"name": "Refining"}, {"name": "Bag-of-words"}, {"name": "Similarity Score"}, {"name": "Extra Resources"}, {"name": "Segmentation Model"}, {"name": "Additional Annotations"}], "links": [{"type": "doi.abstract", "link": "10.1109/CVPR52733.2024.01307", "url": "https://doi.org/10.1109/CVPR52733.2024.01307"}, {"type": "arxiv.abstract", "link": "2306.08832", "url": "https://arxiv.org/abs/2306.08832"}, {"type": "arxiv.pdf", "link": "2306.08832", "url": "https://arxiv.org/pdf/2306.08832.pdf"}, {"type": "dblp.abstract", "link": "conf/cvpr/ZhangAA24", "url": "https://dblp.uni-trier.de/rec/conf/cvpr/ZhangAA24"}, {"type": "pdf", "link": "https://export.arxiv.org/pdf/2306.08832"}, {"type": "semantic_scholar.abstract", "link": "b634f9ba35123d40f0af8d96a9c154025cf2cf2a", "url": "https://www.semanticscholar.org/paper/b634f9ba35123d40f0af8d96a9c154025cf2cf2a"}, {"type": "corpusid", "link": "266573547"}], "flags": [{"name": "validation", "value": 1}], "validated": true, "citation_count": 0, "excerpt": null}, {"paper_id": "962ea29db416f1eddcbc5b91d5ef6086", "title": "Improving Automatic VQA Evaluation Using Large Language Models", "abstract": "8 years after the visual question answering (VQA) task was proposed, accuracy remains the primary metric for automatic evaluation. VQA Accuracy has been effective so far in the IID evaluation setting. However, our community is undergoing a shift towards open-ended generative models and OOD evaluation. In this new paradigm, the existing VQA Accuracy metric is overly stringent and underestimates the performance of VQA systems. Thus, there is a need to develop more robust automatic VQA metrics that serve as a proxy for human judgment. In this work, we propose to leverage the in-context learning capabilities of instruction-tuned large language models (LLMs) to build a better VQA metric. We formulate VQA evaluation as an answer-rating task where the LLM is instructed to score the accuracy of a candidate answer given a set of reference answers. We demonstrate the proposed metric better correlates with human judgment compared to existing metrics across several VQA models and benchmarks. We hope wide adoption of our metric will contribute to better estimating the research progress on the VQA task. We plan to release the evaluation code and collected human judgments.", "authors": [{"author": {"author_id": "a9954c19c19e6d8087c6df8de5d10271", "name": "Oscar Ma\u00f1as", "links": [{"type": "semantic_scholar", "link": "1796269096"}, {"type": "xplore", "link": "37088889151"}]}, "affiliations": [{"institution_id": "200bed81461cad607d593360fe5fcc0a", "name": "Universit\u00e9 de Montr\u00e9al", "category": "unknown"}, {"institution_id": "78a83265183550c66a78ff9b5f9b960f", "name": "Mila", "category": "unknown"}]}, {"author": {"author_id": "916c873352ee355f8aa78e8fdeb6b58f", "name": "Benno Krojer", "links": [{"type": "openreview", "link": "~Benno_Krojer1"}, {"type": "semantic_scholar", "link": "1994697809"}, {"type": "semantic_scholar", "link": "2310235282"}]}, "affiliations": [{"institution_id": "2d64978822ccf8676fd9f98e10c823c2", "name": "McGill University", "category": "unknown"}, {"institution_id": "78a83265183550c66a78ff9b5f9b960f", "name": "Mila", "category": "unknown"}]}, {"author": {"author_id": "8d03287b9ec960332f5641912cd95e56", "name": "Aishwarya Agrawal", "links": [{"type": "bio", "link": "aishwarya-agrawal"}, {"type": "email.mila", "link": "aishwarya.agrawal@mila.quebec"}, {"type": "mag", "link": "2117267436"}, {"type": "openreview", "link": "~Aishwarya_Agrawal1"}, {"type": "semantic_scholar", "link": "2293394830"}, {"type": "semantic_scholar", "link": "2801949"}, {"type": "wpid_en", "link": "38508"}, {"type": "wpid_fr", "link": "38504"}, {"type": "xplore", "link": "37085397548"}, {"type": "xplore", "link": "37085742308"}, {"type": "xplore", "link": "37087883810"}]}, "affiliations": [{"institution_id": "200bed81461cad607d593360fe5fcc0a", "name": "Universit\u00e9 de Montr\u00e9al", "category": "unknown"}, {"institution_id": "78a83265183550c66a78ff9b5f9b960f", "name": "Mila", "category": "unknown"}]}], "releases": [{"venue": {"venue_id": "212fd42873e13b90559f5488a45e3afb", "name": "Proceedings of the AAAI Conference on Artificial Intelligence", "type": "journal", "date": {"text": "2024-03-24", "timestamp": 1711252800, "precision": 3}, "links": [], "publisher": null, "series": "", "volume": null}, "peer_reviewed": true, "status": "published", "pages": null}, {"venue": {"venue_id": "386f82a9f8f0588e88d43b9ca0414402", "name": "AAAI", "type": "journal", "date": {"text": "2024", "timestamp": 1704085200, "precision": 1}, "links": [], "publisher": null, "series": "", "volume": null}, "peer_reviewed": true, "status": "published", "pages": "4171-4179"}], "topics": [{"name": "Computer Science"}], "links": [{"type": "doi.abstract", "link": "10.1609/aaai.v38i5.28212", "url": "https://doi.org/10.1609/aaai.v38i5.28212"}, {"type": "doi.abstract", "link": "10.48550/arXiv.2310.02567", "url": "https://doi.org/10.48550/arXiv.2310.02567"}, {"type": "arxiv.abstract", "link": "2310.02567", "url": "https://arxiv.org/abs/2310.02567"}, {"type": "arxiv.pdf", "link": "2310.02567", "url": "https://arxiv.org/pdf/2310.02567.pdf"}, {"type": "dblp.abstract", "link": "conf/aaai/ManasKA24", "url": "https://dblp.uni-trier.de/rec/conf/aaai/ManasKA24"}, {"type": "dblp.abstract", "link": "journals/corr/abs-2310-02567", "url": "https://dblp.uni-trier.de/rec/journals/corr/abs-2310-02567"}, {"type": "pdf", "link": "https://export.arxiv.org/pdf/2310.02567"}, {"type": "semantic_scholar.abstract", "link": "62e633f4b5cf8bc573e496602d3aa6e5919bbe61", "url": "https://www.semanticscholar.org/paper/62e633f4b5cf8bc573e496602d3aa6e5919bbe61"}, {"type": "corpusid", "link": "263620674"}], "flags": [{"name": "validation", "value": 1}], "validated": true, "citation_count": 0, "excerpt": null}, {"paper_id": "bc5d15706846342e3932fb1801b7101f", "title": "MoqaGPT : Zero-Shot Multi-modal Open-domain Question Answering with Large Language Model", "abstract": "Multi-modal open-domain question answering typically requires evidence retrieval from databases across diverse modalities, such as images, tables, passages, etc. Even Large Language Models (LLMs) like GPT-4 fall short in this task. To enable LLMs to tackle the task in a zero-shot manner, we introduce MoqaGPT, a straightforward and flexible framework. Using a divide-and-conquer strategy that bypasses intricate multi-modality ranking, our framework can accommodate new modalities and seamlessly transition to new models for the task. Built upon LLMs, MoqaGPT retrieves and extracts answers from each modality separately, then fuses this multi-modal information using LLMs to produce a final answer. Our methodology boosts performance on the MMCoQA dataset, improving F1 by +37.91 points and EM by +34.07 points over the supervised baseline. On the MultiModalQA dataset, MoqaGPT surpasses the zero-shot baseline, improving F1 by 9.5 points and EM by 10.1 points, and significantly closes the gap with supervised methods. Our codebase is available at https://github.com/lezhang7/MOQAGPT.", "authors": [{"author": {"author_id": "b30549d291d50cc35e210ecaabbcafed", "name": "Le Zhang", "links": [{"type": "openreview", "link": "~Le_Zhang6"}, {"type": "semantic_scholar", "link": "2108005316"}, {"type": "semantic_scholar", "link": "2119685417"}, {"type": "xplore", "link": "924350237007911"}]}, "affiliations": [{"institution_id": "1738899f40b882ede0540c6f87c0cc7a", "name": "2 Universit\u00e9 de Montr\u00e9al", "category": "academia"}]}, {"author": {"author_id": "99a07f0f5c5ae07cc5c26c321d718038", "name": "Yihong Wu", "links": [{"type": "openreview", "link": "~Yihong_Wu6"}, {"type": "semantic_scholar", "link": "2261148799"}]}, "affiliations": [{"institution_id": "1738899f40b882ede0540c6f87c0cc7a", "name": "2 Universit\u00e9 de Montr\u00e9al", "category": "academia"}]}, {"author": {"author_id": "8299b091a0153b1d163d977740d511e9", "name": "Fengran Mo", "links": [{"type": "openreview", "link": "~Fengran_Mo1"}, {"type": "semantic_scholar", "link": "2007643794"}]}, "affiliations": [{"institution_id": "1738899f40b882ede0540c6f87c0cc7a", "name": "2 Universit\u00e9 de Montr\u00e9al", "category": "academia"}]}, {"author": {"author_id": "c578eaaa83bd7973010e067d4adefc64", "name": "Jian-Yun Nie", "links": [{"type": "openreview", "link": "~Jian-Yun_Nie1"}, {"type": "semantic_scholar", "link": "143619007"}, {"type": "semantic_scholar", "link": "2066549585"}, {"type": "semantic_scholar", "link": "2261086903"}, {"type": "semantic_scholar", "link": "50204644"}]}, "affiliations": [{"institution_id": "1738899f40b882ede0540c6f87c0cc7a", "name": "2 Universit\u00e9 de Montr\u00e9al", "category": "academia"}]}, {"author": {"author_id": "8d03287b9ec960332f5641912cd95e56", "name": "Aishwarya Agrawal", "links": [{"type": "bio", "link": "aishwarya-agrawal"}, {"type": "email.mila", "link": "aishwarya.agrawal@mila.quebec"}, {"type": "mag", "link": "2117267436"}, {"type": "openreview", "link": "~Aishwarya_Agrawal1"}, {"type": "semantic_scholar", "link": "2293394830"}, {"type": "semantic_scholar", "link": "2801949"}, {"type": "wpid_en", "link": "38508"}, {"type": "wpid_fr", "link": "38504"}, {"type": "xplore", "link": "37085397548"}, {"type": "xplore", "link": "37085742308"}, {"type": "xplore", "link": "37087883810"}]}, "affiliations": [{"institution_id": "1738899f40b882ede0540c6f87c0cc7a", "name": "2 Universit\u00e9 de Montr\u00e9al", "category": "academia"}]}], "releases": [{"venue": {"venue_id": "12b551572cca46f23b004a6f24ba9f26", "name": "EMNLP/2023/Conference", "type": "conference", "date": {"text": "2023-10-07", "timestamp": 1696651200, "precision": 3}, "links": [{"type": "openreview-venue", "link": "EMNLP/2023/Conference"}], "publisher": null, "series": "", "volume": "EMNLP Findings 2023"}, "peer_reviewed": true, "status": "published", "pages": null}, {"venue": {"venue_id": "12b551572cca46f23b004a6f24ba9f26", "name": "EMNLP/2023/Conference", "type": "conference", "date": {"text": "2023-10-07", "timestamp": 1696651200, "precision": 3}, "links": [{"type": "openreview-venue", "link": "EMNLP/2023/Conference"}], "publisher": null, "series": "", "volume": "EMNLP Findings 2023"}, "peer_reviewed": true, "status": "accepted", "pages": null}], "topics": [{"name": "Computer Science"}, {"name": "Open-domain question answering"}, {"name": "Large Language Model"}, {"name": "Multimodal"}], "links": [{"type": "doi.abstract", "link": "10.48550/arXiv.2310.13265", "url": "https://doi.org/10.48550/arXiv.2310.13265"}, {"type": "openreview.abstract", "link": "wrBIS6FOfV", "url": "https://openreview.net/forum?id=wrBIS6FOfV"}, {"type": "openreview.pdf", "link": "wrBIS6FOfV", "url": "https://openreview.net/pdf?id=wrBIS6FOfV"}, {"type": "arxiv.abstract", "link": "2310.13265", "url": "https://arxiv.org/abs/2310.13265"}, {"type": "arxiv.pdf", "link": "2310.13265", "url": "https://arxiv.org/pdf/2310.13265.pdf"}, {"type": "dblp.abstract", "link": "journals/corr/abs-2310-13265", "url": "https://dblp.uni-trier.de/rec/journals/corr/abs-2310-13265"}, {"type": "semantic_scholar.abstract", "link": "f90c522b284a6c065fa5126216a26a7415a2b9fa", "url": "https://www.semanticscholar.org/paper/f90c522b284a6c065fa5126216a26a7415a2b9fa"}, {"type": "corpusid", "link": "264406118"}], "flags": [{"name": "validation", "value": 1}], "validated": true, "citation_count": 0, "excerpt": null}, {"paper_id": "a833a58f6b6a36ff82f799bf8c92dd64", "title": "Reassessing Evaluation Practices in Visual Question Answering: A Case Study on Out-of-Distribution Generalization", "abstract": "", "authors": [{"author": {"author_id": "8d03287b9ec960332f5641912cd95e56", "name": "Aishwarya Agrawal", "links": [{"type": "bio", "link": "aishwarya-agrawal"}, {"type": "email.mila", "link": "aishwarya.agrawal@mila.quebec"}, {"type": "mag", "link": "2117267436"}, {"type": "openreview", "link": "~Aishwarya_Agrawal1"}, {"type": "semantic_scholar", "link": "2293394830"}, {"type": "semantic_scholar", "link": "2801949"}, {"type": "wpid_en", "link": "38508"}, {"type": "wpid_fr", "link": "38504"}, {"type": "xplore", "link": "37085397548"}, {"type": "xplore", "link": "37085742308"}, {"type": "xplore", "link": "37087883810"}]}, "affiliations": [{"institution_id": "0a4595cdfa4e6d9d22cc74f6a6a2666f", "name": "Canada CIFAR AI Chair", "category": "unknown"}, {"institution_id": "78a83265183550c66a78ff9b5f9b960f", "name": "Mila", "category": "unknown"}]}, {"author": {"author_id": "99cc56f3121d806f667d56156a84171e", "name": "Ivana Kaji'c", "links": [{"type": "semantic_scholar", "link": "2595569"}]}, "affiliations": [{"institution_id": "0a4595cdfa4e6d9d22cc74f6a6a2666f", "name": "Canada CIFAR AI Chair", "category": "unknown"}, {"institution_id": "78a83265183550c66a78ff9b5f9b960f", "name": "Mila", "category": "unknown"}]}, {"author": {"author_id": "a350c4f2bf429c21a662613bd1dc93d7", "name": "Emanuele Bugliarello", "links": [{"type": "semantic_scholar", "link": "83574123"}]}, "affiliations": [{"institution_id": "0a4595cdfa4e6d9d22cc74f6a6a2666f", "name": "Canada CIFAR AI Chair", "category": "unknown"}, {"institution_id": "78a83265183550c66a78ff9b5f9b960f", "name": "Mila", "category": "unknown"}]}, {"author": {"author_id": "f6b5f1928876459b845783107251dc70", "name": "Elnaz Davoodi", "links": [{"type": "openreview", "link": "~Elnaz_Davoodi2"}, {"type": "semantic_scholar", "link": "3232032"}]}, "affiliations": [{"institution_id": "0a4595cdfa4e6d9d22cc74f6a6a2666f", "name": "Canada CIFAR AI Chair", "category": "unknown"}, {"institution_id": "78a83265183550c66a78ff9b5f9b960f", "name": "Mila", "category": "unknown"}]}, {"author": {"author_id": "993859dc9978357c8268e6c632f37f87", "name": "Anita Gergely", "links": [{"type": "semantic_scholar", "link": "2105841261"}]}, "affiliations": [{"institution_id": "0a4595cdfa4e6d9d22cc74f6a6a2666f", "name": "Canada CIFAR AI Chair", "category": "unknown"}, {"institution_id": "78a83265183550c66a78ff9b5f9b960f", "name": "Mila", "category": "unknown"}]}, {"author": {"author_id": "8e0c85a13771a1911eef194329ae1f64", "name": "Phil Blunsom", "links": [{"type": "semantic_scholar", "link": "1685771"}, {"type": "semantic_scholar", "link": "2283848746"}]}, "affiliations": [{"institution_id": "0a4595cdfa4e6d9d22cc74f6a6a2666f", "name": "Canada CIFAR AI Chair", "category": "unknown"}, {"institution_id": "78a83265183550c66a78ff9b5f9b960f", "name": "Mila", "category": "unknown"}]}, {"author": {"author_id": "9bee6a15036e4785b5f52f237bf48661", "name": "Aida Nematzadeh", "links": [{"type": "semantic_scholar", "link": "3208081"}]}, "affiliations": [{"institution_id": "0a4595cdfa4e6d9d22cc74f6a6a2666f", "name": "Canada CIFAR AI Chair", "category": "unknown"}, {"institution_id": "78a83265183550c66a78ff9b5f9b960f", "name": "Mila", "category": "unknown"}]}], "releases": [{"venue": {"venue_id": "171bc5a1d1292466650aed08b1605844", "name": "Findings of the Association for Computational Linguistics: EACL 2023", "type": "conference", "date": {"text": "2023-05", "timestamp": 1682913600, "precision": 2}, "links": [], "publisher": null, "series": "", "volume": null}, "peer_reviewed": true, "status": "published", "pages": null}], "topics": [{"name": "Computer Science"}], "links": [{"type": "doi.abstract", "link": "10.18653/v1/2023.findings-eacl.90", "url": "https://doi.org/10.18653/v1/2023.findings-eacl.90"}, {"type": "arxiv.abstract", "link": "2205.12191", "url": "https://arxiv.org/abs/2205.12191"}, {"type": "arxiv.pdf", "link": "2205.12191", "url": "https://arxiv.org/pdf/2205.12191.pdf"}, {"type": "dblp.abstract", "link": "conf/eacl/AgrawalKBDGBN23", "url": "https://dblp.uni-trier.de/rec/conf/eacl/AgrawalKBDGBN23"}, {"type": "pdf", "link": "https://aclanthology.org/2023.findings-eacl.90.pdf"}, {"type": "semantic_scholar.abstract", "link": "00e75e39f07967d0808d311cc1ad5f11adf80d33", "url": "https://www.semanticscholar.org/paper/00e75e39f07967d0808d311cc1ad5f11adf80d33"}, {"type": "corpusid", "link": "249017530"}, {"type": "acl", "link": "2023.findings-eacl.90"}], "flags": [{"name": "validation", "value": 1}], "validated": true, "citation_count": 0, "excerpt": null}, {"paper_id": "bdcc5f8d291542bf7ad0ec36480988ab", "title": "MAPL: Parameter-Efficient Adaptation of Unimodal Pre-Trained Models for Vision-Language Few-Shot Prompting", "abstract": "Large pre-trained models have proved to be remarkable zero- and (prompt-based) few-shot learners in unimodal vision and language tasks. We propose MAPL, a simple and parameter-efficient method that reuses frozen pre-trained unimodal models and leverages their strong generalization capabilities in multimodal vision-language (VL) settings. MAPL learns a lightweight mapping between the representation spaces of unimodal models using aligned image-text data, and can generalize to unseen VL tasks from just a few in-context examples. The small number of trainable parameters makes MAPL effective at low-data and in-domain learning. Moreover, MAPL\u2019s modularity enables easy extension to other pre-trained models. Extensive experiments on several visual question answering and image captioning benchmarks show that MAPL achieves superior or competitive performance compared to similar methods while training orders of magnitude fewer parameters. MAPL can be trained in just a few hours using modest computational resources and public datasets. We release our code and pre-trained model weights at https://github.com/oscmansan/mapl.", "authors": [{"author": {"author_id": "a9954c19c19e6d8087c6df8de5d10271", "name": "Oscar Ma\u00f1as", "links": [{"type": "semantic_scholar", "link": "1796269096"}, {"type": "xplore", "link": "37088889151"}]}, "affiliations": [{"institution_id": "1fb8b4e60a6fd94aca7cfbfefd143cbe", "name": "4 Mila, Universit\u00e9 de Montr\u00e9al \u2666 ServiceNow Research \u2665 DeepMind", "category": "academia"}]}, {"author": {"author_id": "d2bc00adb65bbe840037193ff3664993", "name": "Pau Rodriguez", "links": [{"type": "openreview", "link": "~Pau_Rodriguez2"}, {"type": "semantic_scholar", "link": "117849477"}, {"type": "semantic_scholar", "link": "2067974906"}, {"type": "semantic_scholar", "link": "2121428093"}, {"type": "semantic_scholar", "link": "2140428838"}, {"type": "semantic_scholar", "link": "2257190056"}, {"type": "semantic_scholar", "link": "2285026068"}, {"type": "xplore", "link": "37533541500"}]}, "affiliations": [{"institution_id": "1fb8b4e60a6fd94aca7cfbfefd143cbe", "name": "4 Mila, Universit\u00e9 de Montr\u00e9al \u2666 ServiceNow Research \u2665 DeepMind", "category": "academia"}]}, {"author": {"author_id": "c79fe712315e62a0537b9b9779b2cf48", "name": "Saba Ahmadi", "links": [{"type": "semantic_scholar", "link": "12841008"}, {"type": "semantic_scholar", "link": "2120590362"}]}, "affiliations": [{"institution_id": "1fb8b4e60a6fd94aca7cfbfefd143cbe", "name": "4 Mila, Universit\u00e9 de Montr\u00e9al \u2666 ServiceNow Research \u2665 DeepMind", "category": "academia"}]}, {"author": {"author_id": "9bee6a15036e4785b5f52f237bf48661", "name": "Aida Nematzadeh", "links": [{"type": "semantic_scholar", "link": "3208081"}]}, "affiliations": [{"institution_id": "1fb8b4e60a6fd94aca7cfbfefd143cbe", "name": "4 Mila, Universit\u00e9 de Montr\u00e9al \u2666 ServiceNow Research \u2665 DeepMind", "category": "academia"}]}, {"author": {"author_id": "8bed3922c1d6d7b374977ab55d495c34", "name": "Yash Goyal", "links": [{"type": "semantic_scholar", "link": "37226164"}]}, "affiliations": [{"institution_id": "1fb8b4e60a6fd94aca7cfbfefd143cbe", "name": "4 Mila, Universit\u00e9 de Montr\u00e9al \u2666 ServiceNow Research \u2665 DeepMind", "category": "academia"}]}, {"author": {"author_id": "8d03287b9ec960332f5641912cd95e56", "name": "Aishwarya Agrawal", "links": [{"type": "bio", "link": "aishwarya-agrawal"}, {"type": "email.mila", "link": "aishwarya.agrawal@mila.quebec"}, {"type": "mag", "link": "2117267436"}, {"type": "openreview", "link": "~Aishwarya_Agrawal1"}, {"type": "semantic_scholar", "link": "2293394830"}, {"type": "semantic_scholar", "link": "2801949"}, {"type": "wpid_en", "link": "38508"}, {"type": "wpid_fr", "link": "38504"}, {"type": "xplore", "link": "37085397548"}, {"type": "xplore", "link": "37085742308"}, {"type": "xplore", "link": "37087883810"}]}, "affiliations": [{"institution_id": "1fb8b4e60a6fd94aca7cfbfefd143cbe", "name": "4 Mila, Universit\u00e9 de Montr\u00e9al \u2666 ServiceNow Research \u2665 DeepMind", "category": "academia"}]}], "releases": [{"venue": {"venue_id": "77927de1ae66d7e86f1825c05a8880bb", "name": "Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics", "type": "conference", "date": {"text": "2023-05", "timestamp": 1682913600, "precision": 2}, "links": [], "publisher": null, "series": "", "volume": null}, "peer_reviewed": true, "status": "published", "pages": null}], "topics": [{"name": "Computer Science"}], "links": [{"type": "doi.abstract", "link": "10.18653/v1/2023.eacl-main.185", "url": "https://doi.org/10.18653/v1/2023.eacl-main.185"}, {"type": "doi.abstract", "link": "10.48550/arXiv.2210.07179", "url": "https://doi.org/10.48550/arXiv.2210.07179"}, {"type": "arxiv.abstract", "link": "2210.07179", "url": "https://arxiv.org/abs/2210.07179"}, {"type": "arxiv.pdf", "link": "2210.07179", "url": "https://arxiv.org/pdf/2210.07179.pdf"}, {"type": "dblp.abstract", "link": "conf/eacl/ManasLANGA23", "url": "https://dblp.uni-trier.de/rec/conf/eacl/ManasLANGA23"}, {"type": "pdf", "link": "http://export.arxiv.org/pdf/2210.07179"}, {"type": "semantic_scholar.abstract", "link": "1f86bf1e334200ec0481349255559fbfe7a33caa", "url": "https://www.semanticscholar.org/paper/1f86bf1e334200ec0481349255559fbfe7a33caa"}, {"type": "corpusid", "link": "252873086"}, {"type": "acl", "link": "2023.eacl-main.185"}], "flags": [{"name": "validation", "value": 1}], "validated": true, "citation_count": 0, "excerpt": null}, {"paper_id": "8b47021a0443f42f1f142dd0b39933c7", "title": "Measuring Progress in Fine-grained Vision-and-Language Understanding", "abstract": "While pretraining on large-scale image\u2013text data from the Web has facilitated rapid progress on many vision-and-language (V&L) tasks, recent work has demonstrated that pretrained models lack \u201cfine-grained\u201d understanding, such as the ability to recognise relationships, verbs, and numbers in images. This has resulted in an increased interest in the community to either develop new benchmarks or models for such capabilities. To better understand and quantify progress in this direction, we investigate four competitive V&L models on four fine-grained benchmarks. Through our analysis, we find that X-VLM (Zeng et al., 2022) consistently outperforms other baselines, and that modelling innovations can impact performance more than scaling Web data, which even degrades performance sometimes. Through a deeper investigation of X-VLM, we highlight the importance of both novel losses and rich data sources for learning fine-grained skills. Finally, we inspect training dynamics, and discover that for some tasks, performance peaks early in training or significantly fluctuates, never converging.", "authors": [{"author": {"author_id": "a350c4f2bf429c21a662613bd1dc93d7", "name": "Emanuele Bugliarello", "links": [{"type": "semantic_scholar", "link": "83574123"}]}, "affiliations": [{"institution_id": "73381f2809c7ca1e6b90f27bd3309e85", "name": "DeepMind", "category": "unknown"}, {"institution_id": "78068fb52abd9c5b184536a635e74387", "name": "University of Copenhagen", "category": "unknown"}]}, {"author": {"author_id": "87c1189a19cedd37219aced4c7885352", "name": "Laurent Sartran", "links": [{"type": "semantic_scholar", "link": "2247711824"}]}, "affiliations": [{"institution_id": "73381f2809c7ca1e6b90f27bd3309e85", "name": "DeepMind", "category": "unknown"}]}, {"author": {"author_id": "8d03287b9ec960332f5641912cd95e56", "name": "Aishwarya Agrawal", "links": [{"type": "bio", "link": "aishwarya-agrawal"}, {"type": "email.mila", "link": "aishwarya.agrawal@mila.quebec"}, {"type": "mag", "link": "2117267436"}, {"type": "openreview", "link": "~Aishwarya_Agrawal1"}, {"type": "semantic_scholar", "link": "2293394830"}, {"type": "semantic_scholar", "link": "2801949"}, {"type": "wpid_en", "link": "38508"}, {"type": "wpid_fr", "link": "38504"}, {"type": "xplore", "link": "37085397548"}, {"type": "xplore", "link": "37085742308"}, {"type": "xplore", "link": "37087883810"}]}, "affiliations": [{"institution_id": "73381f2809c7ca1e6b90f27bd3309e85", "name": "DeepMind", "category": "unknown"}]}, {"author": {"author_id": "af00f4bd2030a19d355726792b2aef9d", "name": "Lisa Anne Hendricks", "links": [{"type": "semantic_scholar", "link": "2234342"}, {"type": "semantic_scholar", "link": "2258347245"}]}, "affiliations": [{"institution_id": "73381f2809c7ca1e6b90f27bd3309e85", "name": "DeepMind", "category": "unknown"}]}, {"author": {"author_id": "9bee6a15036e4785b5f52f237bf48661", "name": "Aida Nematzadeh", "links": [{"type": "semantic_scholar", "link": "3208081"}]}, "affiliations": [{"institution_id": "73381f2809c7ca1e6b90f27bd3309e85", "name": "DeepMind", "category": "unknown"}]}], "releases": [{"venue": {"venue_id": "42e31f2f32a5357e63034ccc49a1b6db", "name": "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "type": "conference", "date": {"text": "2023-07", "timestamp": 1688184000, "precision": 2}, "links": [], "publisher": null, "series": "", "volume": null}, "peer_reviewed": true, "status": "published", "pages": null}], "topics": [{"name": "Computer Science"}], "links": [{"type": "doi.abstract", "link": "10.18653/v1/2023.acl-long.87", "url": "https://doi.org/10.18653/v1/2023.acl-long.87"}, {"type": "doi.abstract", "link": "10.48550/arXiv.2305.07558", "url": "https://doi.org/10.48550/arXiv.2305.07558"}, {"type": "arxiv.abstract", "link": "2305.07558", "url": "https://arxiv.org/abs/2305.07558"}, {"type": "arxiv.pdf", "link": "2305.07558", "url": "https://arxiv.org/pdf/2305.07558.pdf"}, {"type": "dblp.abstract", "link": "conf/acl/BugliarelloSAHN23", "url": "https://dblp.uni-trier.de/rec/conf/acl/BugliarelloSAHN23"}, {"type": "pdf", "link": "http://export.arxiv.org/pdf/2305.07558"}, {"type": "semantic_scholar.abstract", "link": "65051f6836a4a618586c01deff43b46ab5e3f887", "url": "https://www.semanticscholar.org/paper/65051f6836a4a618586c01deff43b46ab5e3f887"}, {"type": "corpusid", "link": "258676204"}, {"type": "acl", "link": "2023.acl-long.87"}], "flags": [{"name": "validation", "value": 1}], "validated": true, "citation_count": 0, "excerpt": null}]
