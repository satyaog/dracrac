[{"paper_id": "dd747c83d75a00a0733d75304fab4b3a", "title": "Contrasting Intra-Modal and Ranking Cross-Modal Hard Negatives to Enhance Visio-Linguistic Compositional Understanding", "abstract": "Vision-Language Models (VLMs), such as CLIP, exhibit strong image-text comprehension abilities, facilitating advances in several downstream tasks such as zero-shot image classification, image-text retrieval, and text-to-image generation. However, the compositional reasoning abilities of existing VLMs remains subpar. The root of this limitation lies in the inadequate alignment between the images and captions in the pretraining datasets. Additionally, the current contrastive learning objective fails to focus on fine-grained grounding components like relations, actions, and attributes, resulting in\"bag-of-words\"representations. We introduce a simple and effective method to improve compositional reasoning in VLMs. Our method better leverages available datasets by refining and expanding the standard image-text contrastive learning framework. Our approach does not require specific annotations and does not incur extra parameters. When integrated with CLIP, our technique yields notable improvement over state-of-the-art baselines across five vision-language compositional benchmarks. We open-source our code at https://github.com/lezhang7/Enhance-FineGrained.", "authors": [{"author": {"author_id": "b30549d291d50cc35e210ecaabbcafed", "name": "Le Zhang", "links": [{"type": "openreview", "link": "~Le_Zhang6"}, {"type": "semantic_scholar", "link": "2108005316"}, {"type": "semantic_scholar", "link": "2119685417"}, {"type": "xplore", "link": "924350237007911"}]}, "affiliations": [{"institution_id": "200bed81461cad607d593360fe5fcc0a", "name": "Universit\u00e9 de Montr\u00e9al", "category": "unknown"}, {"institution_id": "2e7644e4488777eb735a190201699cd0", "name": "Mila - Quebec AI Institute", "category": "unknown"}]}, {"author": {"author_id": "89ad0b796b9cf0d8f6f4bc86305989d7", "name": "Rabiul Awal", "links": [{"type": "semantic_scholar", "link": "66736108"}, {"type": "xplore", "link": "37089703671"}]}, "affiliations": [{"institution_id": "200bed81461cad607d593360fe5fcc0a", "name": "Universit\u00e9 de Montr\u00e9al", "category": "unknown"}, {"institution_id": "2e7644e4488777eb735a190201699cd0", "name": "Mila - Quebec AI Institute", "category": "unknown"}]}, {"author": {"author_id": "8d03287b9ec960332f5641912cd95e56", "name": "Aishwarya Agrawal", "links": [{"type": "bio", "link": "aishwarya-agrawal"}, {"type": "email.mila", "link": "aishwarya.agrawal@mila.quebec"}, {"type": "mag", "link": "2117267436"}, {"type": "openreview", "link": "~Aishwarya_Agrawal1"}, {"type": "semantic_scholar", "link": "2293394830"}, {"type": "semantic_scholar", "link": "2801949"}, {"type": "wpid_en", "link": "38508"}, {"type": "wpid_fr", "link": "38504"}, {"type": "xplore", "link": "37085397548"}, {"type": "xplore", "link": "37085742308"}, {"type": "xplore", "link": "37087883810"}]}, "affiliations": [{"institution_id": "200bed81461cad607d593360fe5fcc0a", "name": "Universit\u00e9 de Montr\u00e9al", "category": "unknown"}, {"institution_id": "2e7644e4488777eb735a190201699cd0", "name": "Mila - Quebec AI Institute", "category": "unknown"}]}], "releases": [{"venue": {"venue_id": "283d81814812d4b8bf8437c0e9a08bbf", "name": "2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)", "type": "journal", "date": {"text": "2024-06-16", "timestamp": 1718510400, "precision": 3}, "links": [], "publisher": "IEEE", "series": "", "volume": null}, "peer_reviewed": true, "status": "published", "pages": "13774-13784"}, {"venue": {"venue_id": "67289e6c8c6151e2d53cf4da29397244", "name": "CVPR", "type": "journal", "date": {"text": "2024", "timestamp": 1704085200, "precision": 1}, "links": [], "publisher": null, "series": "", "volume": null}, "peer_reviewed": true, "status": "published", "pages": "13774-13784"}, {"venue": {"venue_id": "6a10336ac4067994ec7d75d4c91b6dd3", "name": "ArXiv", "type": "preprint", "date": {"text": "2023-06-15", "timestamp": 1686801600, "precision": 3}, "links": [], "publisher": null, "series": "", "volume": null}, "peer_reviewed": false, "status": "preprint", "pages": null}], "topics": [{"name": "Negative Type"}, {"name": "Stable Training"}, {"name": "Segmented Regression"}, {"name": "Bag-of-words Model"}, {"name": "contrastive learning"}, {"name": "Adaptive Threshold"}, {"name": "Progressive Training"}, {"name": "Contrastive Learning"}, {"name": "Computer Science"}, {"name": "Annotations"}, {"name": "Ranking Loss"}, {"name": "Cognition"}, {"name": "Contrast Objective"}, {"name": "Benchmark testing"}, {"name": "Self-supervised Learning"}, {"name": "Scene Graph"}, {"name": "Text to image"}, {"name": "True Pairs"}, {"name": "Contrastive Loss"}, {"name": "Image Classification"}, {"name": "COCO Dataset"}, {"name": "Hinge Loss"}, {"name": "Upper Bound"}, {"name": "Language Model"}, {"name": "Specific Annotation"}, {"name": "Threshold Regression"}, {"name": "compositional understanding"}, {"name": "Curriculum Learning"}, {"name": "Vision-language models"}, {"name": "Image Generation"}, {"name": "Contrastive learning"}, {"name": "Semantics"}, {"name": "Comprehensive Dataset"}, {"name": "Visual Question Answering"}, {"name": "Refining"}, {"name": "Bag-of-words"}, {"name": "Similarity Score"}, {"name": "Extra Resources"}, {"name": "Segmentation Model"}, {"name": "Additional Annotations"}], "links": [{"type": "doi.abstract", "link": "10.1109/CVPR52733.2024.01307", "url": "https://doi.org/10.1109/CVPR52733.2024.01307"}, {"type": "arxiv.abstract", "link": "2306.08832", "url": "https://arxiv.org/abs/2306.08832"}, {"type": "arxiv.pdf", "link": "2306.08832", "url": "https://arxiv.org/pdf/2306.08832.pdf"}, {"type": "dblp.abstract", "link": "conf/cvpr/ZhangAA24", "url": "https://dblp.uni-trier.de/rec/conf/cvpr/ZhangAA24"}, {"type": "pdf", "link": "https://export.arxiv.org/pdf/2306.08832"}, {"type": "semantic_scholar.abstract", "link": "b634f9ba35123d40f0af8d96a9c154025cf2cf2a", "url": "https://www.semanticscholar.org/paper/b634f9ba35123d40f0af8d96a9c154025cf2cf2a"}, {"type": "corpusid", "link": "266573547"}], "flags": [{"name": "validation", "value": 1}], "validated": true, "citation_count": 0, "excerpt": null},{"paper_id": "962ea29db416f1eddcbc5b91d5ef6086", "title": "Improving Automatic VQA Evaluation Using Large Language Models", "abstract": "8 years after the visual question answering (VQA) task was proposed, accuracy remains the primary metric for automatic evaluation. VQA Accuracy has been effective so far in the IID evaluation setting. However, our community is undergoing a shift towards open-ended generative models and OOD evaluation. In this new paradigm, the existing VQA Accuracy metric is overly stringent and underestimates the performance of VQA systems. Thus, there is a need to develop more robust automatic VQA metrics that serve as a proxy for human judgment. In this work, we propose to leverage the in-context learning capabilities of instruction-tuned large language models (LLMs) to build a better VQA metric. We formulate VQA evaluation as an answer-rating task where the LLM is instructed to score the accuracy of a candidate answer given a set of reference answers. We demonstrate the proposed metric better correlates with human judgment compared to existing metrics across several VQA models and benchmarks. We hope wide adoption of our metric will contribute to better estimating the research progress on the VQA task. We plan to release the evaluation code and collected human judgments.", "authors": [{"author": {"author_id": "a9954c19c19e6d8087c6df8de5d10271", "name": "Oscar Ma\u00f1as", "links": [{"type": "semantic_scholar", "link": "1796269096"}, {"type": "xplore", "link": "37088889151"}]}, "affiliations": [{"institution_id": "200bed81461cad607d593360fe5fcc0a", "name": "Universit\u00e9 de Montr\u00e9al", "category": "unknown"}, {"institution_id": "78a83265183550c66a78ff9b5f9b960f", "name": "Mila", "category": "unknown"}]}, {"author": {"author_id": "916c873352ee355f8aa78e8fdeb6b58f", "name": "Benno Krojer", "links": [{"type": "openreview", "link": "~Benno_Krojer1"}, {"type": "semantic_scholar", "link": "1994697809"}, {"type": "semantic_scholar", "link": "2310235282"}]}, "affiliations": [{"institution_id": "2d64978822ccf8676fd9f98e10c823c2", "name": "McGill University", "category": "unknown"}, {"institution_id": "78a83265183550c66a78ff9b5f9b960f", "name": "Mila", "category": "unknown"}]}, {"author": {"author_id": "8d03287b9ec960332f5641912cd95e56", "name": "Aishwarya Agrawal", "links": [{"type": "bio", "link": "aishwarya-agrawal"}, {"type": "email.mila", "link": "aishwarya.agrawal@mila.quebec"}, {"type": "mag", "link": "2117267436"}, {"type": "openreview", "link": "~Aishwarya_Agrawal1"}, {"type": "semantic_scholar", "link": "2293394830"}, {"type": "semantic_scholar", "link": "2801949"}, {"type": "wpid_en", "link": "38508"}, {"type": "wpid_fr", "link": "38504"}, {"type": "xplore", "link": "37085397548"}, {"type": "xplore", "link": "37085742308"}, {"type": "xplore", "link": "37087883810"}]}, "affiliations": [{"institution_id": "200bed81461cad607d593360fe5fcc0a", "name": "Universit\u00e9 de Montr\u00e9al", "category": "unknown"}, {"institution_id": "78a83265183550c66a78ff9b5f9b960f", "name": "Mila", "category": "unknown"}]}], "releases": [{"venue": {"venue_id": "212fd42873e13b90559f5488a45e3afb", "name": "Proceedings of the AAAI Conference on Artificial Intelligence", "type": "journal", "date": {"text": "2024-03-24", "timestamp": 1711252800, "precision": 3}, "links": [], "publisher": null, "series": "", "volume": null}, "peer_reviewed": true, "status": "published", "pages": null}, {"venue": {"venue_id": "386f82a9f8f0588e88d43b9ca0414402", "name": "AAAI", "type": "journal", "date": {"text": "2024", "timestamp": 1704085200, "precision": 1}, "links": [], "publisher": null, "series": "", "volume": null}, "peer_reviewed": true, "status": "published", "pages": "4171-4179"}, {"venue": {"venue_id": "45ac772c31fab2f984bbb5d527fe2c8a", "name": "ArXiv", "type": "preprint", "date": {"text": "2023-10-04", "timestamp": 1696392000, "precision": 3}, "links": [], "publisher": null, "series": "", "volume": null}, "peer_reviewed": false, "status": "preprint", "pages": null}], "topics": [{"name": "Computer Science"}], "links": [{"type": "doi.abstract", "link": "10.1609/aaai.v38i5.28212", "url": "https://doi.org/10.1609/aaai.v38i5.28212"}, {"type": "doi.abstract", "link": "10.48550/arXiv.2310.02567", "url": "https://doi.org/10.48550/arXiv.2310.02567"}, {"type": "arxiv.abstract", "link": "2310.02567", "url": "https://arxiv.org/abs/2310.02567"}, {"type": "arxiv.pdf", "link": "2310.02567", "url": "https://arxiv.org/pdf/2310.02567.pdf"}, {"type": "dblp.abstract", "link": "conf/aaai/ManasKA24", "url": "https://dblp.uni-trier.de/rec/conf/aaai/ManasKA24"}, {"type": "dblp.abstract", "link": "journals/corr/abs-2310-02567", "url": "https://dblp.uni-trier.de/rec/journals/corr/abs-2310-02567"}, {"type": "pdf", "link": "https://export.arxiv.org/pdf/2310.02567"}, {"type": "semantic_scholar.abstract", "link": "62e633f4b5cf8bc573e496602d3aa6e5919bbe61", "url": "https://www.semanticscholar.org/paper/62e633f4b5cf8bc573e496602d3aa6e5919bbe61"}, {"type": "corpusid", "link": "263620674"}], "flags": [{"name": "validation", "value": 1}], "validated": true, "citation_count": 0, "excerpt": null}]